{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5hvo8QWN-a9"
   },
   "source": [
    "# Installing Whisper\n",
    "\n",
    "Make sure that you've already installed properly unto your virtual (venv) environment the current version of Whisper with hooks enabled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IMEkgyagYto"
   },
   "source": [
    "# Loading a Dataset and Running with Hooks\n",
    "\n",
    "Run a couple tests to make sure that whisper is properlly hooked up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3CqtR2Fi5-vP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/WhisperLens/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 1])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 3, 3])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 4])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 5])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 6])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 7])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 8])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 9])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 10])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 11])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 12])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 13])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 14])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 15])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 16])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 17])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 18])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 19])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 20])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 21])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 22])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 23])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 24])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 25])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 26])\n",
      "Shape at hookpoint decoder.blocks.0.attn.hook_attn_pattern: torch.Size([1, 8, 1, 27])\n",
      "Transcription: {'text': ' Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 5.44, 'text': ' Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.', 'tokens': [50364, 2221, 13, 2326, 388, 391, 307, 264, 50244, 295, 264, 2808, 5359, 11, 293, 321, 366, 5404, 281, 2928, 702, 14943, 13, 50636], 'temperature': 0.0, 'avg_logprob': -0.21808563232421874, 'compression_ratio': 1.0864197530864197, 'no_speech_prob': 0.007444924209266901}], 'language': 'en'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-30 17:19:07.104204: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-30 17:19:07.117523: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-30 17:19:07.121952: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-30 17:19:07.131767: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-30 17:19:07.827789: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "You have passed language=en, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of language=en.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison HF Transcription: ['<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.']\n",
      "****************************************************************************************************\n",
      "{'text': ' And so my fellow Americans ask not what your country can do for you, ask what you can do for your country.', 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 7.6000000000000005, 'text': ' And so my fellow Americans ask not what your country can do for you,', 'tokens': [50364, 400, 370, 452, 7177, 6280, 1029, 406, 437, 428, 1941, 393, 360, 337, 291, 11, 50744], 'temperature': 0.0, 'avg_logprob': -0.396818259666706, 'compression_ratio': 1.3417721518987342, 'no_speech_prob': 0.09160678088665009}, {'id': 1, 'seek': 0, 'start': 7.6000000000000005, 'end': 10.6, 'text': ' ask what you can do for your country.', 'tokens': [50744, 1029, 437, 291, 393, 360, 337, 428, 1941, 13, 50894], 'temperature': 0.0, 'avg_logprob': -0.396818259666706, 'compression_ratio': 1.3417721518987342, 'no_speech_prob': 0.09160678088665009}], 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "#### A: Test that running with the hooks context works ####\n",
    "# 1. Imports\n",
    "import torch\n",
    "import whisper\n",
    "import datasets\n",
    "import numpy as np\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from pathlib import Path\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "\n",
    "# print(Path.cwd()) # This should give you .../WhisperLens/notebooks\n",
    "\n",
    "# 2. Get a dataset\n",
    "ds = datasets.load_dataset(\n",
    "    \"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\"\n",
    ")\n",
    "sample = ds[0][\n",
    "    \"audio\"\n",
    "]  # This should be an element with a numpy array, basically (and some other metadata)\n",
    "\n",
    "\n",
    "# 3. Define a hook that we can use to test that hooks work at all\n",
    "def print_shape_hook(activation: torch.Tensor, hook: HookPoint):\n",
    "    print(f\"Shape at hookpoint {hook.name}: {activation.shape}\")\n",
    "\n",
    "\n",
    "# 4. Load a model and then just run it with a hook\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# NOTE: You should see a bunch of print statements of pytorch shape tuples coming out here, followed by a reasonable\n",
    "# result (check the HF repo for that). Then you should see NOTHING coming out when you are running the second time\n",
    "# (but the result should be more or less reasonable)\n",
    "print(\"*\" * 100)\n",
    "with model.hooks(\n",
    "    fwd_hooks=[(\"decoder.blocks.0.attn.hook_attn_pattern\", print_shape_hook)]\n",
    "):\n",
    "    result = model.transcribe(sample[\"array\"].astype(np.float32))\n",
    "print(\"Transcription:\", result)\n",
    "# Compare with the HF Model\n",
    "comparison_processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "comparison_model = WhisperForConditionalGeneration.from_pretrained(\n",
    "    \"openai/whisper-small\"\n",
    ")\n",
    "input_features = comparison_processor(\n",
    "    sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\"\n",
    ").input_features\n",
    "predicted_ids = comparison_model.generate(input_features, language=\"en\")\n",
    "transcription = comparison_processor.batch_decode(\n",
    "    predicted_ids, skip_special_tokens=False\n",
    ")\n",
    "print(\"Comparison HF Transcription:\", transcription)\n",
    "\n",
    "# No hooks:\n",
    "print(\"*\" * 100)\n",
    "# Check that you have the flac file proprly in the tests directory\n",
    "result = model.transcribe(\n",
    "    # Root directory of the repo.\n",
    "    (Path().cwd().parent / \"tests\" / \"jfk.flac\").as_posix()\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/WhisperLens/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/WhisperLens/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 3, 3])\n",
      "SHAPE OF V IS torch.Size([1, 6, 3, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 3, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 3, 3])\n",
      "SHAPE OF V IS torch.Size([1, 6, 3, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 3, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 3, 3])\n",
      "SHAPE OF V IS torch.Size([1, 6, 3, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 3, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 3, 3])\n",
      "SHAPE OF V IS torch.Size([1, 6, 3, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 3, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 4, 4])\n",
      "SHAPE OF V IS torch.Size([1, 6, 4, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 4, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 4, 4])\n",
      "SHAPE OF V IS torch.Size([1, 6, 4, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 4, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 4, 4])\n",
      "SHAPE OF V IS torch.Size([1, 6, 4, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 4, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 4, 4])\n",
      "SHAPE OF V IS torch.Size([1, 6, 4, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 4, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 5, 5])\n",
      "SHAPE OF V IS torch.Size([1, 6, 5, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 5, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 5, 5])\n",
      "SHAPE OF V IS torch.Size([1, 6, 5, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 5, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 5, 5])\n",
      "SHAPE OF V IS torch.Size([1, 6, 5, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 5, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 5, 5])\n",
      "SHAPE OF V IS torch.Size([1, 6, 5, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 5, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 6, 6])\n",
      "SHAPE OF V IS torch.Size([1, 6, 6, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 6, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 6, 6])\n",
      "SHAPE OF V IS torch.Size([1, 6, 6, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 6, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 6, 6])\n",
      "SHAPE OF V IS torch.Size([1, 6, 6, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 6, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 6, 6])\n",
      "SHAPE OF V IS torch.Size([1, 6, 6, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 6, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 7, 7])\n",
      "SHAPE OF V IS torch.Size([1, 6, 7, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 7, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 7, 7])\n",
      "SHAPE OF V IS torch.Size([1, 6, 7, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 7, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 7, 7])\n",
      "SHAPE OF V IS torch.Size([1, 6, 7, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 7, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 7, 7])\n",
      "SHAPE OF V IS torch.Size([1, 6, 7, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 7, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 8, 8])\n",
      "SHAPE OF V IS torch.Size([1, 6, 8, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 8, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 8, 8])\n",
      "SHAPE OF V IS torch.Size([1, 6, 8, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 8, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 8, 8])\n",
      "SHAPE OF V IS torch.Size([1, 6, 8, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 8, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 8, 8])\n",
      "SHAPE OF V IS torch.Size([1, 6, 8, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 8, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 9, 9])\n",
      "SHAPE OF V IS torch.Size([1, 6, 9, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 9, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 9, 9])\n",
      "SHAPE OF V IS torch.Size([1, 6, 9, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 9, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 9, 9])\n",
      "SHAPE OF V IS torch.Size([1, 6, 9, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 9, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 9, 9])\n",
      "SHAPE OF V IS torch.Size([1, 6, 9, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 9, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 10, 10])\n",
      "SHAPE OF V IS torch.Size([1, 6, 10, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 10, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 10, 10])\n",
      "SHAPE OF V IS torch.Size([1, 6, 10, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 10, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 10, 10])\n",
      "SHAPE OF V IS torch.Size([1, 6, 10, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 10, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 10, 10])\n",
      "SHAPE OF V IS torch.Size([1, 6, 10, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 10, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 11, 11])\n",
      "SHAPE OF V IS torch.Size([1, 6, 11, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 11, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 11, 11])\n",
      "SHAPE OF V IS torch.Size([1, 6, 11, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 11, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 11, 11])\n",
      "SHAPE OF V IS torch.Size([1, 6, 11, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 11, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 11, 11])\n",
      "SHAPE OF V IS torch.Size([1, 6, 11, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 11, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 12, 12])\n",
      "SHAPE OF V IS torch.Size([1, 6, 12, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 12, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 12, 12])\n",
      "SHAPE OF V IS torch.Size([1, 6, 12, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 12, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 12, 12])\n",
      "SHAPE OF V IS torch.Size([1, 6, 12, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 12, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 12, 12])\n",
      "SHAPE OF V IS torch.Size([1, 6, 12, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 12, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 1500, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 13, 13])\n",
      "SHAPE OF V IS torch.Size([1, 6, 13, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 13, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 13, 13])\n",
      "SHAPE OF V IS torch.Size([1, 6, 13, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 13, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 13, 13])\n",
      "SHAPE OF V IS torch.Size([1, 6, 13, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 13, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 13, 13])\n",
      "SHAPE OF V IS torch.Size([1, 6, 13, 64])\n",
      "W SHAPE IS torch.Size([1, 6, 13, 1500])\n",
      "SHAPE OF V IS torch.Size([1, 6, 1500, 64])\n",
      "Logits shape: torch.Size([1, 13, 51865])\n",
      "Activations type: <class 'dict'>\n",
      "Ingoing tokens: <|startoftranscript|><|en|><|transcribe|><|notimestamps|> Mr. Quilter is the apostle of\n",
      "Logits (should be tokens shifted by 1): <|en|><|transcribe|><|notimestamps|> Mr. Quilter is the apostle of the\n",
      "LAST Logit: e\n",
      "Activations (shapes):\n",
      "╒═════════════════════════════════════════════════════╤════════════════════════════════╕\n",
      "│ Layer                                               │ Shape                          │\n",
      "╞═════════════════════════════════════════════════════╪════════════════════════════════╡\n",
      "│ encoder.hook_conv1_pre                              │ torch.Size([1, 80, 3000])      │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.hook_conv1_post_pre_act                     │ torch.Size([1, 384, 3000])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.hook_conv2_pre                              │ torch.Size([1, 384, 3000])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.hook_conv2_post_pre_act                     │ torch.Size([1, 384, 1500])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.hook_conv2_post_post_act                    │ torch.Size([1, 384, 1500])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.hook_post_pos_embd_add                      │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.hook_resid_pre                     │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.hook_attn_ln_post                  │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.attn.hook_q                        │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.attn.hook_k                        │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.attn.hook_v                        │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.attn.hook_attn_scores              │ torch.Size([1, 6, 1500, 1500]) │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.attn.hook_attn_scores_masked       │ torch.Size([1, 6, 1500, 1500]) │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.attn.hook_attn_pattern             │ torch.Size([1, 6, 1500, 1500]) │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.attn.hook_attn_result              │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.hook_resid_mid                     │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.hook_mlp_ln_post                   │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.hook_mlp_up_post                   │ torch.Size([1, 1500, 1536])    │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.hook_mlp_act_post                  │ torch.Size([1, 1500, 1536])    │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.hook_mlp_down_post                 │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.0.hook_resid_post                    │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.hook_resid_pre                     │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.hook_attn_ln_post                  │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.attn.hook_q                        │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.attn.hook_k                        │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.attn.hook_v                        │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.attn.hook_attn_scores              │ torch.Size([1, 6, 1500, 1500]) │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.attn.hook_attn_scores_masked       │ torch.Size([1, 6, 1500, 1500]) │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.attn.hook_attn_pattern             │ torch.Size([1, 6, 1500, 1500]) │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.attn.hook_attn_result              │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.hook_resid_mid                     │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.hook_mlp_ln_post                   │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.hook_mlp_up_post                   │ torch.Size([1, 1500, 1536])    │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.hook_mlp_act_post                  │ torch.Size([1, 1500, 1536])    │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.hook_mlp_down_post                 │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.1.hook_resid_post                    │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.hook_resid_pre                     │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.hook_attn_ln_post                  │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.attn.hook_q                        │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.attn.hook_k                        │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.attn.hook_v                        │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.attn.hook_attn_scores              │ torch.Size([1, 6, 1500, 1500]) │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.attn.hook_attn_scores_masked       │ torch.Size([1, 6, 1500, 1500]) │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.attn.hook_attn_pattern             │ torch.Size([1, 6, 1500, 1500]) │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.attn.hook_attn_result              │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.hook_resid_mid                     │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.hook_mlp_ln_post                   │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.hook_mlp_up_post                   │ torch.Size([1, 1500, 1536])    │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.hook_mlp_act_post                  │ torch.Size([1, 1500, 1536])    │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.hook_mlp_down_post                 │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.2.hook_resid_post                    │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.hook_resid_pre                     │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.hook_attn_ln_post                  │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.attn.hook_q                        │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.attn.hook_k                        │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.attn.hook_v                        │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.attn.hook_attn_scores              │ torch.Size([1, 6, 1500, 1500]) │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.attn.hook_attn_scores_masked       │ torch.Size([1, 6, 1500, 1500]) │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.attn.hook_attn_pattern             │ torch.Size([1, 6, 1500, 1500]) │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.attn.hook_attn_result              │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.hook_resid_mid                     │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.hook_mlp_ln_post                   │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.hook_mlp_up_post                   │ torch.Size([1, 1500, 1536])    │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.hook_mlp_act_post                  │ torch.Size([1, 1500, 1536])    │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.hook_mlp_down_post                 │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.blocks.3.hook_resid_post                    │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ encoder.hook_ln_post_post                           │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.hook_tokens                                 │ torch.Size([1, 13])            │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.hook_resid_pre                     │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.hook_attn_ln_post                  │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.attn.hook_q                        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.attn.hook_k                        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.attn.hook_v                        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.attn.hook_attn_scores              │ torch.Size([1, 6, 13, 13])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.attn.hook_attn_scores_masked       │ torch.Size([1, 6, 13, 13])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.attn.hook_attn_pattern             │ torch.Size([1, 6, 13, 13])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.attn.hook_attn_result              │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.hook_resid_mid                     │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.hook_x_attn_ln_post                │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.cross_attn.hook_q                  │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.cross_attn.hook_k                  │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.cross_attn.hook_v                  │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.cross_attn.hook_attn_scores        │ torch.Size([1, 6, 13, 1500])   │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.cross_attn.hook_attn_scores_masked │ torch.Size([1, 6, 13, 1500])   │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.cross_attn.hook_attn_pattern       │ torch.Size([1, 6, 13, 1500])   │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.cross_attn.hook_attn_result        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.hook_x_resid_mid                   │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.hook_mlp_ln_post                   │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.hook_mlp_up_post                   │ torch.Size([1, 13, 1536])      │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.hook_mlp_act_post                  │ torch.Size([1, 13, 1536])      │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.hook_mlp_down_post                 │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.0.hook_resid_post                    │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.hook_resid_pre                     │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.hook_attn_ln_post                  │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.attn.hook_q                        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.attn.hook_k                        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.attn.hook_v                        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.attn.hook_attn_scores              │ torch.Size([1, 6, 13, 13])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.attn.hook_attn_scores_masked       │ torch.Size([1, 6, 13, 13])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.attn.hook_attn_pattern             │ torch.Size([1, 6, 13, 13])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.attn.hook_attn_result              │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.hook_resid_mid                     │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.hook_x_attn_ln_post                │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.cross_attn.hook_q                  │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.cross_attn.hook_k                  │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.cross_attn.hook_v                  │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.cross_attn.hook_attn_scores        │ torch.Size([1, 6, 13, 1500])   │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.cross_attn.hook_attn_scores_masked │ torch.Size([1, 6, 13, 1500])   │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.cross_attn.hook_attn_pattern       │ torch.Size([1, 6, 13, 1500])   │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.cross_attn.hook_attn_result        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.hook_x_resid_mid                   │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.hook_mlp_ln_post                   │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.hook_mlp_up_post                   │ torch.Size([1, 13, 1536])      │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.hook_mlp_act_post                  │ torch.Size([1, 13, 1536])      │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.hook_mlp_down_post                 │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.1.hook_resid_post                    │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.hook_resid_pre                     │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.hook_attn_ln_post                  │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.attn.hook_q                        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.attn.hook_k                        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.attn.hook_v                        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.attn.hook_attn_scores              │ torch.Size([1, 6, 13, 13])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.attn.hook_attn_scores_masked       │ torch.Size([1, 6, 13, 13])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.attn.hook_attn_pattern             │ torch.Size([1, 6, 13, 13])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.attn.hook_attn_result              │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.hook_resid_mid                     │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.hook_x_attn_ln_post                │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.cross_attn.hook_q                  │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.cross_attn.hook_k                  │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.cross_attn.hook_v                  │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.cross_attn.hook_attn_scores        │ torch.Size([1, 6, 13, 1500])   │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.cross_attn.hook_attn_scores_masked │ torch.Size([1, 6, 13, 1500])   │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.cross_attn.hook_attn_pattern       │ torch.Size([1, 6, 13, 1500])   │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.cross_attn.hook_attn_result        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.hook_x_resid_mid                   │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.hook_mlp_ln_post                   │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.hook_mlp_up_post                   │ torch.Size([1, 13, 1536])      │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.hook_mlp_act_post                  │ torch.Size([1, 13, 1536])      │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.hook_mlp_down_post                 │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.2.hook_resid_post                    │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.hook_resid_pre                     │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.hook_attn_ln_post                  │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.attn.hook_q                        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.attn.hook_k                        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.attn.hook_v                        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.attn.hook_attn_scores              │ torch.Size([1, 6, 13, 13])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.attn.hook_attn_scores_masked       │ torch.Size([1, 6, 13, 13])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.attn.hook_attn_pattern             │ torch.Size([1, 6, 13, 13])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.attn.hook_attn_result              │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.hook_resid_mid                     │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.hook_x_attn_ln_post                │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.cross_attn.hook_q                  │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.cross_attn.hook_k                  │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.cross_attn.hook_v                  │ torch.Size([1, 1500, 384])     │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.cross_attn.hook_attn_scores        │ torch.Size([1, 6, 13, 1500])   │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.cross_attn.hook_attn_scores_masked │ torch.Size([1, 6, 13, 1500])   │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.cross_attn.hook_attn_pattern       │ torch.Size([1, 6, 13, 1500])   │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.cross_attn.hook_attn_result        │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.hook_x_resid_mid                   │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.hook_mlp_ln_post                   │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.hook_mlp_up_post                   │ torch.Size([1, 13, 1536])      │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.hook_mlp_act_post                  │ torch.Size([1, 13, 1536])      │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.hook_mlp_down_post                 │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.blocks.3.hook_resid_post                    │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.hook_ln_post                                │ torch.Size([1, 13, 384])       │\n",
      "├─────────────────────────────────────────────────────┼────────────────────────────────┤\n",
      "│ decoder.hook_logits                                 │ torch.Size([1, 13, 51865])     │\n",
      "╘═════════════════════════════════════════════════════╧════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "#### B: Test that we are able to do exactly ONE step of inference OK and get all the activations ####\n",
    "import torch\n",
    "import whisper\n",
    "import datasets\n",
    "import einops\n",
    "import numpy as np\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from pathlib import Path\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from whisper import DecodingOptions\n",
    "from whisper.decoding import DecodingTask\n",
    "from whisper.audio import log_mel_spectrogram, pad_or_trim\n",
    "from whisper.tokenizer import get_tokenizer\n",
    "from tabulate import tabulate  # Visualize shapes as they go through the network\n",
    "\n",
    "# Get one sample\n",
    "ds = datasets.load_dataset(\n",
    "    \"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\"\n",
    ")\n",
    "sample = ds[0][\"audio\"][\"array\"].astype(np.float32)\n",
    "\n",
    "# Calculate the audio features and default tokens like in\n",
    "# https://github.com/openai/whisper/blob/main/whisper/decoding.py#L737\n",
    "# TODO(Adriano) try prompting?\n",
    "# https://github.com/openai/whisper/blob/ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab/whisper/decoding.py#L101\n",
    "model = whisper.load_model(\"tiny\")  # To be safe, do tiny\n",
    "decoding_options = DecodingOptions(\n",
    "    task=\"transcribe\",\n",
    "    language=\"en\",\n",
    "    sample_len=1,\n",
    "    beam_size=1,\n",
    "    without_timestamps=False,\n",
    ")\n",
    "decoding_task = DecodingTask(model, decoding_options)\n",
    "# NOTE _get_audio_features runs forward pass of encoder: it's a misnomer; don't use it!\n",
    "# Defaults should \"just work\"...\n",
    "padded_sample = pad_or_trim(sample)\n",
    "audio_features = log_mel_spectrogram(audio=padded_sample)\n",
    "audio_features = einops.rearrange(audio_features, \"seq d -> 1 seq d\").to(model.device)\n",
    "tokens = torch.tensor(decoding_task._get_initial_tokens())\n",
    "tokens = einops.rearrange(tokens, \"seq -> 1 seq\").to(model.device)\n",
    "\n",
    "# Run a few times so that we can start to see interesting tokens\n",
    "num_runs_before_read = 10\n",
    "predicted_tokens = []\n",
    "for _ in range(num_runs_before_read):\n",
    "    logits = model(audio_features, tokens)\n",
    "    assert len(tokens.shape) == 2 and tokens.shape[0] == 1\n",
    "    assert logits.shape[:2] == (1, tokens.shape[-1]), f\"Logits shape: {logits.shape}, len of tokens: {tokens.shape[-1]}\"\n",
    "    most_likely_token = logits[0][-1].argmax(dim=-1).item()\n",
    "    tokens = torch.cat([tokens, torch.tensor([[most_likely_token]]).to(model.device)], dim=-1)\n",
    "\n",
    "# Run with cache\n",
    "with torch.no_grad():\n",
    "    # First try checking that we only print ONCE\n",
    "    logits, acts = model.run_with_cache(\n",
    "        audio_features,\n",
    "        tokens,\n",
    "    )\n",
    "    print(\"Logits shape:\", logits.shape)\n",
    "    print(\"Activations type:\", type(acts))\n",
    "\n",
    "    max_idx = logits[0].argmax(dim=-1).tolist()\n",
    "    # TODO(Adriano) why the hell is it doing translate and not english when I do multilingual=False?\n",
    "    tokenizer = get_tokenizer(\n",
    "        multilingual=True,\n",
    "        # multilingual=False,\n",
    "        # num_languages=1,\n",
    "        # language=\"en\",\n",
    "        # task=\"transcribe\",\n",
    "    )\n",
    "    tok = tokenizer.encoding.decode(tokens[0].tolist())\n",
    "    max_tok = tokenizer.encoding.decode(max_idx)\n",
    "    # Expect to see some shit about Mr. Quilter\n",
    "    print(\"Ingoing tokens:\", tok)\n",
    "    print(\"Logits (should be tokens shifted by 1):\", max_tok)\n",
    "    print(\"LAST Logit:\", max_tok[-1])\n",
    "    \n",
    "    print(\"Activations (shapes):\")\n",
    "    header = [\"Layer\", \"Shape\"]\n",
    "    rows = [[f\"{k}\", f\"{v.shape}\"] for k, v in acts.items()]\n",
    "    print(tabulate(rows, headers=header, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do we use causal attention?\n",
    "As a short demonstration of hooks in action, we check whether or not causal attention is used in a few different places (which you can see in the table above in you ran the previous cell):\n",
    "- encoder.blocks.0.attn.hook_attn_pattern\n",
    "- decoder.blocks.0.attn.hook_attn_patter\n",
    "- decoder.blocks.0.cross_attn.hook_attn_pattern\n",
    "\n",
    "We run the full inference process and then simply take the logical AND of whether it is causal. It is very unlikely that it will be zero always and not be causal (and if it's ever not zero, then it's probably not causal).\n",
    "\n",
    "Unlike the GPT-series and most LLMs, you'll note that whisper is NOT causal, but it does have one causal portion: the self-attention for text. It works like this:\n",
    "1. Independently encode the entire sound-wave signal using a non-causal transformer.\n",
    "2. Do a language model generation conditioned on the output from 1. This involves blocks in which each step is either:\n",
    "    - Causal self-attention like GPT2\n",
    "    - Cross-attention with results from 1 (not causal: it gets to \"listen ahead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Result:  Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.\n",
      "****************************************************************************************************\n",
      "Table for Encoder (zero means probably causal, all other numbers -> not causal):\n",
      "╒═════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│         │   Head 0 │   Head 1 │    Head 2 │    Head 3 │    Head 4 │    Head 5 │\n",
      "╞═════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ Layer 0 │ 0.112061 │ 0.18335  │ 0.995117  │ 0.0205688 │ 0.581055  │ 0.0248566 │\n",
      "├─────────┼──────────┼──────────┼───────────┼───────────┼───────────┼───────────┤\n",
      "│ Layer 1 │ 0.546387 │ 0.101074 │ 0.226196  │ 0.273926  │ 0.0568542 │ 0.0964355 │\n",
      "├─────────┼──────────┼──────────┼───────────┼───────────┼───────────┼───────────┤\n",
      "│ Layer 2 │ 0.964844 │ 0.384277 │ 0.0700073 │ 0.486816  │ 0.955566  │ 0.956543  │\n",
      "├─────────┼──────────┼──────────┼───────────┼───────────┼───────────┼───────────┤\n",
      "│ Layer 3 │ 0.158081 │ 0.895996 │ 0.707031  │ 0.193481  │ 0.729492  │ 0.791016  │\n",
      "╘═════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╛\n",
      "****************************************************************************************************\n",
      "Table for Decoder (zero means probably causal, all other numbers -> not causal):\n",
      "╒═════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│         │   Head 0 │   Head 1 │   Head 2 │   Head 3 │   Head 4 │   Head 5 │\n",
      "╞═════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Layer 0 │        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├─────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Layer 1 │        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├─────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Layer 2 │        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "├─────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Layer 3 │        0 │        0 │        0 │        0 │        0 │        0 │\n",
      "╘═════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "****************************************************************************************************\n",
      "Table for Decoder-X (zero means probably causal, all other numbers -> not causal):\n",
      "╒═════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╕\n",
      "│         │   Head 0 │   Head 1 │   Head 2 │   Head 3 │   Head 4 │    Head 5 │\n",
      "╞═════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╡\n",
      "│ Layer 0 │ 0.154175 │ 0.111511 │ 0.157227 │ 0.152222 │ 0.612305 │ 0.0738525 │\n",
      "├─────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────┤\n",
      "│ Layer 1 │ 0.161865 │ 0.865723 │ 0.59082  │ 0.101929 │ 0.106079 │ 0.30127   │\n",
      "├─────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────┤\n",
      "│ Layer 2 │ 0.630371 │ 0.137329 │ 0.311768 │ 0.213501 │ 0.159668 │ 0.611816  │\n",
      "├─────────┼──────────┼──────────┼──────────┼──────────┼──────────┼───────────┤\n",
      "│ Layer 3 │ 0.276123 │ 0.561035 │ 0.280273 │ 0.337402 │ 0.372314 │ 0.247437  │\n",
      "╘═════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import whisper\n",
    "import re\n",
    "import numpy as np\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from datasets import load_dataset\n",
    "from tabulate import tabulate\n",
    "\n",
    "# 1. Dataset\n",
    "dname = \"hf-internal-testing/librispeech_asr_dummy\"\n",
    "ds = load_dataset(dname, \"clean\", split=\"validation\")\n",
    "sample = ds[0][\"audio\"][\"array\"].astype(np.float32)\n",
    "\n",
    "# 2. Model\n",
    "model = whisper.load_model(\"tiny\")\n",
    "\n",
    "# 3. Hooks\n",
    "assert len(model.encoder.blocks) > 0 and len(model.decoder.blocks) > 0\n",
    "n_heads_encoder = model.encoder.blocks[0].attn.n_head\n",
    "n_heads_decoder = model.decoder.blocks[0].attn.n_head\n",
    "n_layers_encoder = len(model.encoder.blocks)\n",
    "n_layers_decoder = len(model.decoder.blocks)\n",
    "\n",
    "# NOTE that we always have the same number of heads in the tiny model\n",
    "encoder_heads_are_causal = [[0 for _ in range(n_heads_encoder)] for _ in range(n_layers_encoder)]\n",
    "decoder_heads_are_causal = [[0 for _ in range(n_heads_decoder)] for _ in range(n_layers_decoder)]\n",
    "decoder_x_heads_are_causal = [[0 for _ in range(n_heads_decoder)] for _ in range(n_layers_decoder)]\n",
    "\n",
    "def is_probably_causal(\n",
    "        act: torch.Tensor,\n",
    "        hook: HookPoint\n",
    "    ) -> None:\n",
    "    hookname = hook.name\n",
    "    assert hookname is not None and len(re.findall(\"blocks\\.\\d+\", hookname)) == 1, hookname\n",
    "    _, right, = hookname.split(\"blocks.\", 1)\n",
    "    block_int, _ = right.split(\".\", 1)\n",
    "    block_int = int(block_int)\n",
    "\n",
    "    is_encoder = \"encoder\" in hookname\n",
    "    is_x = \"cross_attn\" in hookname\n",
    "    assert is_encoder and not is_x or not is_encoder\n",
    "\n",
    "    # 1. NOT X-Attn (X means that it might not be the same seq)\n",
    "    assert len(act.shape) == 4\n",
    "    mask = torch.triu(torch.ones(act.shape[-2], act.shape[-1]), diagonal=1).to(act.device)\n",
    "    assert mask[0][0] == 0 # Sanity check\n",
    "    for head_int in range(n_heads_encoder if is_encoder else n_heads_decoder):\n",
    "        head = act[:, head_int, :, :]\n",
    "        if is_encoder:\n",
    "            encoder_heads_are_causal[block_int][head_int] = (head * mask).abs().max().item()\n",
    "        elif not is_encoder and not is_x:\n",
    "            decoder_heads_are_causal[block_int][head_int] = (head * mask).abs().max().item()\n",
    "        else:\n",
    "            decoder_x_heads_are_causal[block_int][head_int] = (head * mask).abs().max().item()\n",
    "\n",
    "\n",
    "hook_points = (\n",
    "      [f\"encoder.blocks.{i}.attn.hook_attn_pattern\" for i in range(n_layers_encoder)]\n",
    "    + [f\"decoder.blocks.{i}.attn.hook_attn_pattern\" for i in range(n_layers_decoder)]\n",
    "    + [f\"decoder.blocks.{i}.cross_attn.hook_attn_pattern\" for i in range(n_layers_decoder)]\n",
    ")\n",
    "tables = [\n",
    "    encoder_heads_are_causal,\n",
    "    decoder_heads_are_causal,\n",
    "    decoder_x_heads_are_causal,\n",
    "]\n",
    "table_names = [\n",
    "    \"Encoder\",\n",
    "    \"Decoder\",\n",
    "    \"Decoder-X\",\n",
    "]\n",
    "\n",
    "# 4. Run\n",
    "with model.hooks(\n",
    "    fwd_hooks=[(hook_point, is_probably_causal) for hook_point in hook_points]\n",
    "):\n",
    "    # NOTE set the \"decoding_options\" kwarg for no_kv_cache since otherwise\n",
    "    # our ativations are all sorts of fucked up\n",
    "    result = model.transcribe(sample, no_kv_cache=True)\n",
    "\n",
    "# Sanity check the result is the same when you are not using kv caching\n",
    "print(\"*\"*100)\n",
    "print(\"Result:\", result['text'])\n",
    "\n",
    "# 5. Showcase\n",
    "for name, table in zip(table_names, tables):\n",
    "    print(\"*\" * 100)\n",
    "    print(f\"Table for {name} (zero means probably causal, all other numbers -> not causal):\")\n",
    "    header = [\"\"] + [f\"Head {i}\" for i in range(len(table[0]))]\n",
    "    rows = [[f\"Layer {i}\"] + [f\"{v}\" for v in row] for i, row in enumerate(table)]\n",
    "    print(tabulate(rows, headers=header, tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "039b53f2702c4179af7e0548018d0588": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06b9aa5f49fa44ba8c93b647dc7db224": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0d10a42c753453283e5219c22239337",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09f4cb79ff86465aaf48b0de24869af9",
      "value": 164
     }
    },
    "09a29a91f58d4462942505a3cc415801": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_83391f98a240490987c397048fc1a0d4",
       "IPY_MODEL_06b9aa5f49fa44ba8c93b647dc7db224",
       "IPY_MODEL_da9c231ee67047fb89073c95326b72a5"
      ],
      "layout": "IPY_MODEL_48da931ebe7f4fd299f8c98c7d2460ff"
     }
    },
    "09f4cb79ff86465aaf48b0de24869af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b9cecf5b3584fba8258a81d4279a25b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39f5a6ae8ba74c8598f9c6d5b8ad2d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48da931ebe7f4fd299f8c98c7d2460ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a901f447c1d477bb49f954e0feacedd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83391f98a240490987c397048fc1a0d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a901f447c1d477bb49f954e0feacedd",
      "placeholder": "​",
      "style": "IPY_MODEL_39f5a6ae8ba74c8598f9c6d5b8ad2d65",
      "value": "100%"
     }
    },
    "a0d10a42c753453283e5219c22239337": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da9c231ee67047fb89073c95326b72a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b9cecf5b3584fba8258a81d4279a25b",
      "placeholder": "​",
      "style": "IPY_MODEL_039b53f2702c4179af7e0548018d0588",
      "value": " 164/164 [05:08&lt;00:00,  1.86s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
